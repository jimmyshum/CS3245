This is the README file for A0121310J's and A0121098J's submission

Matric number : A0121310J, A0121098J
Email : A0121310@nus.edu.sg, A0121098@nus.edu.sg

== General Notes about this assignment ==

Place your comments or requests here for Min to read.  Discuss your
architecture or experiments in general.  A paragraph or two is usually
sufficient.

Our way to search relevant patents is to use the title field as query, 
and do searching on patents titles and description (abstract field). 
We didn’t use the description field because there are lots of word 
(more ltc.lnc calculation). It would slow down the search process. 
Second reason is that the return document set is too large if we 
don’t do stop word handling. It almost return all 2244 patents every time.

For the search, we used vector space model( ltc.lnc ranking scheme).
Unlike Hw3, all the documents containing one or more keywords from
the query will be returned.

The dictionary generated contain document frequency for each term. 
Stemming and nltk.tokenizer are used to reduce the dictionary size. 
The posting file contain DocID and term frequency for each terms. 

One thing special is that for terms appeared in title, its frequency
 would have a bonus. One appearance in title field would equivalent to
 10 appearance in description field. 
It helps true positive documents to get a higher ranks after our testing.


In index.py, the main function is index(..). It first gets the list of 
documents from the directory using function get_doc_list(). For each
xml file, etree.parser() is used to generate a xml tree. The content form
title tag and description tag is extracted by function- xpath(). 

After tokenization and stemming of the title string. It count term’s 
frequency (with bonus: 10). Then the term frequency is added to the 
dictionary and posting on the memory. 

Repeat the same thing for descriptions string (without bonus count). 
Then, the dictionary and positing are writer to the txt files.



In search.py, a main function inside is called search(…). For implementing the document scoring environment and the itc-inc ranking scheme , several functions have been coded.
For the query side,'calWTFT()' is for calculating the term frequency of the query. 'normalization()' is for normalizing the result. 

For the document side, The 'idf_from_df()' is for retrieving the document frequency (df), 'tf_from_raw()' is for getting the term frequency from the input file, and the 'get_doc_itc()' is getting the document itc. The get_checking_doc_list is to generate the common term list for both query side and the document side .the 'product()' is for calculating the doc product between the query vector and the document vector. . After running all the functions, the result of itc-inc ranking list is generated and stored for comparison. 

Finally, all documents will be put into the output file in decreasing order of this final score.


== Files included with this submission ==

List the files in your submission here and provide a short 1 line
description of each file.  Make sure your submission's files are named
and formatted correctly.

index.py	The program for indexing the dictionary and posting list
search.py  	The program for searching patents using the dictionary and posting.
README.txt	The current file

dictionary.txt	file storing the dictionary  generated by index.py (Incomplete)
postings.txt	file storing the posting list generated by index.py (Incomplete)


== Statement of individual work ==

Please initial one of the following statements.

[X] We, A0121310J, A0121098J certify that We have followed the CS 3245 Information
Retrieval class guidelines for homework assignments.  In particular, We
expressly vow that we have followed the Facebook rule in discussing
with others in doing the assignment and did not take notes (digital or
printed) from the discussions.  

[ ] We, A0121310J, did not follow the class rules regarding homework
assignment, because of the following reason:

<Please fill in>

I suggest that I should be graded as follows:

<Please fill in>

== References ==

<Please list any websites and/or people you consulted with for this
assignment and state their role>
http://docs.python.org/
http://stackoverflow.com/
http://lxml.de/tutorial.html 
